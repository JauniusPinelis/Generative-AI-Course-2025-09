Week 1:

Day 1:
- ChatGPT usage
- What is LLM
- What is AI platform
- Gen-AI as a technology
- LLMs

Day 2:
- ChatGPT models: GPT-4o, GPT-4.1, GPT-4o mini
- The pricing of input and output tokens
- The concepts of tools in LLMs
- Web search tool
- Memory tool

Day 3:
- ChatGPT Code-interpreter tools
- The weaknesses of LLMs
- LLM is just probability machine
- Hallucinations
- Knowledge limitations of LLMs
- Limited context size

Day 4:
- The prompting techniques
- Context clears
- System Instructions
- One shot vs Few shot prompting
- Chain of thought technique
- Working with files of text
- LLMs are expensive
- Practical tips for using ChatGPT

Week 2: ChatGPT alternatives

Day 1: Google AI Studio
- Google AI platform
- Reasoning models
- Google AI platform capabilities

Day 2: Other LLM platforms
- Anthropic and the Claude LLMs
- Grok platform
- LLM proxy services
- OpenRouter platform

Day 3: Open source LLMs
- Commercial vs Open Source models
- Why are LLMs expensive?
- What are the requirements to have them run locally
- Hugging Face ecosystem

Day 4: Run open-source models with Ollama
- Downloading and installing Ollama from https://ollama.com/
- Running open source models on your computer
- The business applications of open-source models

Week 3: GenAI in Software development

Day 1: Vibe coding
- What is Vibe coding
- Vibe coding with Visual Studio and Github Copilot
- Create basic applications with natural language
- How to fix errors with Vibe coding
- How to update existing application with Vibe coding

Day 2: Vibe coding tools
- Github Copilot intro
- Cursor intro
- Claude Code
- Gemini CLI
- The benefits and dangers of these tools in IT

Day 3: Tools and APIs
- Recap what is a tool in Generative AI
- Intro to LLMs and system-to-system communications
- Intro to REST APIs

Day 4: Vibe coding and API practice
- Create a website which shows the weather forecast and the selected coordinates
- System analysis
- Front-end and Backend

Week 4: Model Context Protocol

Day 1: Software building AI as a service
- API Recap
- Technology as a service
- Creating apps with Lovable.AI
- Builder.AI scandal

Day 2: The rise of Model Context Protocol (MCP)
- What is MCP
- Why is MCP needed?
- MCP gives us tools
- Technology is becoming 'LLM friendly'
- The influence of Anthropic to the AI ecosystem

Day 3: The power of MCP tools
- Browse various tools in https://smithery.ai/
- Empower Visual Studio to send emails with Gmail MCP
- Context7 MCP and documentation for LLMs
- Pitfalls and security concerns of MCPs

Day 4: MCP in practice
- Practical work
- Empower your Cursor/VSCode with Context7 to overcome outdated LLM information
- Intro to Streamlit
- Building a sample chatbot with Streamlit and using Context7

Week 5: Retrieval Augmentation Generation (RAG)

Day 1: RAG intro
- What is Retrieval Augmentation Generation
- Why is it the most widely used LLM technique in the industry
- Context management
- The challenges of RAG
- How to make LLM an expert of domain

Day 2: Langchain and the challenges of data
- Different formats of data and its challenges: txt, md, pdf, html
- How Langchain helps here
- How to provide the knowledge and the data.
- Correct data is the key.

Day 3: Intro to databases
- Install PostgreSQL database
- PostgreSQL UI vs Server
- Running PostgreSQL
- Relational databases
- Data vs Schema
- LLM Embeddings and Vector databases

Day 4: Practical: RAG practice with Langchain
- Building domain expert chatbot with Langchain and Streamlit
- Using different models with Langchain.

Week 6: AI agents and automation

Day 1: No Code/Low Code platforms
- Introduction to n8n
- Building your own RAG with no-code in n8n
- n8n integrations with differents services.

Day 2: Introduction to AI agents
- What is an AI agent
- 2025 is the year of AI agents
- Why business require the AI agents.
- The needs for 'AI engineer'
- LLM vs AI agent?
- AI agents vs AI systems

Day 3: OpenAI agent SDK
- Intro to AI agents frameworks.
- Why are they needed.
- Analyzing and building a 'deep research' agent with openai agent sdk.

Day4 : (Practice) Data analyst agent
- Postgre database recap
- Restoring a sample database
- Building a Streamlit agent which is able to analyse the database on natural language queries

Week 7: Training (fine-tuning) your own model

Day 1: Training model theory
  - Training from scratch is super complex.
  - Fine-tuning is a better option.
  - Why and when fine-tune
  - Fine-tuning vs RAG
  - The challenges of fine-tuning.
  - Base vs Instructions models.
  - HuggingFace intro

Day 2: Preparation for fine-tuning
  - Hugging face analysis
  - Datasets
  - Model classifications
  - Ollama recap and why is it needed.
  - Google notebooks and the need of GPU

Day 3 Finetuning demo
  - Fine-tuning as a service in OpenAI
  - Unsloth framework
  - Unsloth the documentation
  - Choosing the right model for fine-tuning.
  - Finetuning LLama3.2
  - Testing the fine-tuned model
  - Launching the fine-tuned model with Ollama.
  
Day 4 finetuning-practice  
  - Modification of the dataset.
  - Fine-tuning practice with Unsloth framework
  - new model upload to HuggingFace
  

Week 8 Multimodal models

Day 1 Vision analysis and image generation

Day 2 Voice generation agents



